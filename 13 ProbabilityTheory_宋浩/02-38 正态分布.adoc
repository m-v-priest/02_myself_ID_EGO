
= 连续概率分布 : 正态分布
:toc: left
:toclevels: 3
:sectnums:

---

== ★ Mathematica 和 Geogebra 中, "正态分布"的用法





image:img/0680.png[,]

image:img/0681.png[,]



---

== 解释

=== 解释 (刘嘉概率讲座)

==== 正态分布 有三个数学性质

正态分布, 是概率分布中最重要的分布。在数学家眼里,它是远远高于其他分布的。*有很多其他的分布，比如对数正态分布、T分布、F分布, 都是直接由"正态分布"推导出来的。*

正态分布, normal distribution, 直译过来就是"最常态下的分布", "一般的分布".

正态分布的 f(x)曲线 : +
横坐标, 代表随机变量的取值范围，越往右，随机变量的值就越大; +
纵坐标，则代表概率的大小，最底下的概率是0， 越往上概率越大。

这样，从曲线上随便找一点，确定它的横坐标、纵坐标，我们就知道了这个值出现的概率是多少。

因为这条曲线是左右对称的，所以**中间的最高点，就代表平均值出现的概率最大，数据最多.** 而两边陡峭下降，就意味着: *越靠近平均值，数据越多; 越远离平均值，数据就越少。*


正态分布 有三个数学性质:

[options="autowidth"]
|===
|Header 1 |Header 2

|性质1 : 均值就是期望. 它们重合在同一点处 -- 即"曲线中间的最高点"的x坐标处.
|数学期望, 代表长期的价值. 在正态分布中，平均值就能代表随机事件的长期价值。

为什么我们会用高考的平均成绩，衡量一所高中的教学质量?为什么我们会用平均收益率，衡量一家基金公司的好坏? 原因很简单，高考成绩和基金公司的收益，都是服从"正态分布"的。

|性质2 : 极端值很少.
|正态分布的图形, 越靠近平均值，这条曲线越高，出现的概率越大; 越远离平均值，这条曲线就越低，出现的概率就越小。这就说明，正态分布的大多数数据, 都集中在平均值附近，极端值很少。

“极端值很少”这句话，有两层含义:  +
一是**极端值出现的概率很低**， +
二是**极端值对均值的影响很小。**

也因此，正态分布是非常稳定的。拿人的身高来说吧，它大体服从正态分布，所以即使姚明加入我们课程,我们的平均身高也不会有太大变化 (即: 极端值对均值的影响很小)。

|性质3: 标准差决定曲线的胖瘦。
|正态分布曲线，有的形状要矮胖一些，有的要高瘦一点，为什么呢? 原因就是"标准差"不同. +
标准差越大，数据的波动越剧烈，钟形曲线就越矮胖 (即x轴的横跨幅度越大); +
标准差越小，波动就越小, 数据就越集中，钟形曲线就越高瘦 (即x轴的横跨幅度越窄)。
|===

所以为什么说"正态分布"简单? 就是因为在正态分布中，"平均值"等于"期望"，它决定了这条曲线的最高点; "方差"决定胖瘦，它决定曲线的弯曲度。简单这两个数据，就确定了这条曲线的形状。

一些软件, 告诉你开机时间多少秒, 打败了全国97%的用户, 这个是怎么算出来的? 就是利用了"正态分布模型". 只要随机抽取一部分用户的开机数据，算出"均值"和"标准差",就可以确定一条正态分布曲线。*在正态分布中，一个标准差, 覆盖68.26%的数据; 两个标准差, 覆盖95.44%的数据. 软件只需要比较你的开机时间和均值的差距，就能知道你距离均值多少个标准差，也就知道你的排名了。*

image:img/0600.webp[,]

**所以, 正态分布，为我们提供了一个估算个体在整体中位置的便捷方法。**像智商、身高、考试成绩，只要服从正态分布，我们就都能这样快速得到答案。


不同的正态分布曲线, 也能比较:
[options="autowidth"  cols="1a,1a"]
|===
|Header 1 |Header 2

|- 标准差相同, 均值不同, 能比较"好坏".
|因为均值即"期望", 期望就代表"长期价值". 两个事物的期望不同, 自然它们的好坏也不同.

|- 均值相同, 标准差不同, 能比较波动. 即风险性.
|
比如, 假若男女智商的正态分布曲线如下,

image:img/0601.png[,]

能看出:

- 两者的均值相同. 说明男女智商没有高低之分.
- 但高矮胖瘦不一样(即"标准差"不一样, 波动程度不一样), 男性智商的波动性更大, 说明在智商高的人中间，男性的数量要多于女性; 当然，智商平平的人中间，男性也同样比女性多。


|- 均值和标准差, 都不同. 那也能比较"专业和业余"
|比如, 某体育项目, 你和世界冠军同台比赛, 他比你得分高(期望大), 又成绩稳定(方差小), 所以这两项都比你强, 就说明他比你"专业". +
所以, 专业就是"均值更高，标准差更小"，业余则恰恰相反。
|===



==== "正态分布"的数学证明, 就是"中心极限定理".

image:img/0602.png[,]

对于任何数据科学家来说，核心工具都是"直方图". 直方图的核心目的是了解给定数据集的分布
 直方图表示在x轴上找到的变量，其不同值在y轴上出现的次数。

中心极限定理的表述方式有好几种，但核心的数学性质只有一条 —— 大量独立的随机变量相加, 无论各个随机变量的分布是怎样的，它们相加的结果, 必定会趋向于"正态分布"。换句话说,正态分布是必然产生的。

*中心极限定理告诉我们，只要随机事件是有很多独立的因素共同作用决定的,无论每个因素本身是什么分布,这个随机事件最终都会形成正态分布。*

比如，影响人身高的因素很多，营养、遗传、环境、族裔、性别等都有影响,这些因素的综合效果, 就使人的身高服从正态分布。 +
影响考试成绩的因素也很多，自身的能力、家庭教育、智商、专注力,甚至考前的情绪、身体状况等也都有影响，但当这些因素加在一起,考试成绩就服从正态分布。

*世界上为什么会有这么多"正态分布"? 就是因为很多事情都是多个随机因素共同作用的结果。*

*因为任何分布叠加, 最终都会形成正态分布，所以无论是"对数分布"还是"幂律分布"，无论是"指数分布"还是其他什么分布，只要自身不断演化，不断自己叠加自己，最终也一样会变成正态分布。或许我们可以这么说，所有的分布，不是"正态分布",就是在变成"正态分布"的路上。*

*当然,现实世界里，影响一个随机事件的各种因素，不可能完全是理想状态下的"相互独立"，而是互相影响的,所以我们身边依然存在各种各样的其他分布.*


话说回来, "中心极限定理"是因，"正态分布"是果。正因为中心极限定理存在，所以正态分布才必然正确。



==== 当我们不知道某个随机事件服从什么分布的时候, 最常见的方法就是假设它服从正态分布,然后再用数据验证。

为什么要假设它服从正态分布呢? 因为:

1. 由于正态分布非常常见，所以假设一个随机事件服从正态分布,比假设其他分布的成功率更高。

2. 如果我们验证后发现，这个随机事件不服从"正态分布"，那它就一定不满足正态分布背后的"中心极限定理"。既然它不满足中心极限定理，那我们就知道 -- 要么是它的影响因素不够多，要么是各种影响因素不相互独立，要么是某种影响因素的影响力太大等等... 这就为我们接下来的研究, 指明了方向。


==== 正态分布是世界的归宿

信息论领域中, 发现了“嫡最大原理”。也就是说,在一个孤立系统中，嫡总是在不断增大。而**"正态分布", 是所有已知均值和方差的分布中，信息嫡最大的一种分布。**这就意味着: 如果"嫡不断增长"是孤立系统确定的演化方向，那嫡的最大化，也就是"正态分布"，就是孤立系统演化的必然结果。


---

== 抛硬币的例子

image:img/0370.png[,]

image:img/0371.png[,]

image:img/0372.png[,]

image:img/0373.png[,]

image:img/0374.png[,]

image:img/0375.png[,]

image:img/0376.png[,]

image:img/0377.png[,]

image:img/0378.png[,]

image:img/0379.png[,]

image:img/0380.png[,]

image:img/0381.png[,]

image:img/0382.png[,]

image:img/0383.png[,]

image:img/0384.png[,]

image:img/0385.png[,]

image:img/0386.png[,]

image:img/0387.png[,]

image:img/0388.png[,]

image:img/0389.png[,]

image:img/0390.png[,]

image:img/0391.png[,]

image:img/0392.png[,]

image:img/0393.png[,]

image:img/0394.png[,]

image:img/0395.png[,]

image:img/0396.png[,]







---

== 正态分布 Normal distribution -> stem:[ X ~ N(μ, σ^2)]

[options="autowidth" cols="1a,1a"]
|===
|Header 1 |Header 2

|正态分布（Normal distribution）
|也称“常态分布”，又名高斯分布（Gaussian distribution）. 这是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。

|正态曲线(钟形曲线)
|正态曲线, 呈钟型. 两头低，中间高，左右对称. 因其曲线呈钟形，因此人们又经常称之为"钟形曲线"。

以身高为例，服从正态分布, 意味着大部分人的身高, 都会在人群的平均身高上下波动，特别矮和特别高的都比较少见。

|"连续型随机变量"分布 -- 不关注“点概率”，只关注“区间概率”
|*正态分布属于“连续型随机变量分布”这类. 对于"连续型随机变量"，我们不关注“点概率”，只关注“区间概率”.*

例如, 假定随机变量X 是指“北京市成年男子的身高”，理论上它可以取任意正数，所以我们把它当做一个"连续型随机变量"（连续型变量，就是指可以取某一区间或整个实数轴上的任意一个值的变量）来看待。

这里，我们先想一想如何计算P(X =1.87)? 即身高恰好完全exactly等于1.87的概率是多少，这就是所谓的“点概率”。更极端一点，让随机变量Y是[0,1]这个区间上的任意一点，那么Y的取值有多少个呢？无数多. 所以Y 取某一个具体的值的概率, 是1除以无数，结果就可以看做是0。于是，这里透露一个很重要的结论：**连续型随机变量取任意"某个确定的值"的概率, 均为0。**因此，*对于连续型随机变量，我们通常不研究它取"某个特定值"的概率，而研究它在"某一段区间"上的取值*，比如身高在1.70～1.80的概率。

|正态分布的"概率密度曲线" -- 即钟形曲线
|正态分布的"概率密度曲线", 就是那条中间高、两边低的“钟形曲线”.

上面我们讲了区间概率，这里你就**可以通过区间的角度, 来理解"概率密度曲线"：曲线越高，也就代表着这个区间的概率越密集**. 简单理解成在同样大小的房子里，这个房间的人数更多、更挤。

|概率密度函数-- 积分（面积）等于概率
|另**一个关于"概率密度函数" Probability Density Function 的重要知识点是: 积分（面积）等于概率。**

*随机变量X, 在某个区间比如（a，b）即a<X<b的概率，就是"概率密度曲线"在这个区间下的面积.* 数学上的表达就是: **密度函数在区间（a， b）上的积分。** 所以，*概率的大小, 就是“概率密度函数曲线下的面积”的大小*，这个概念, 会对我们之后理解假设中的“拒绝域”有帮助。

下图中的三条曲线f (x)，就是概率密度函数，各种形式的概率就是相对应的曲线下面积。

image:img/0157.jpg[,]

image:img/0168.jpg[,]

image:img/0167.jpg[,]

image:img/0169.jpg[,]



|均值μ, 标准差σ
|**一旦谈到"正态分布"，我们首先要想到它的两个参数："均值μ"是多少, 和"标准差σ"是几。** 因为这两个数才是我们运用"正态分布"解决实际问题的“利器”。

- *一旦"均值μ"和"标准差σ"确定，"正态分布曲线"也就确定.*

image:img/0158.jpg[,]


---

均值μ

- *概率密度曲线, 在"均值μ"处达到最大，并且对称.*
- *"均值μ"可取实数轴上的任意数值，均值μ"决定了"正态曲线"的具体位置*.

---

标准差σ



---


- *正态随机变量, 在特定区间上的取值概率, 由正态曲线下的面积给出. 而且其曲线下的总面积(即积分)等于1.*

- 当X的取值, 向横轴左右两个方向无限延伸时，曲线的两个尾端, 也无限渐近横轴，理论上永远不会与之相交.

- *"标准差σ"决定了曲线的“陡峭”或“扁平”程度 -- 标准差σ 越大，"正态曲线"就越扁平；标准差σ 越小，"正态曲线"就越陡峭。*

这是因为，标准差σ越小，就意味着大多数变量值, 离"均数μ"的距离越短，因此大多数值都紧密地聚集在"均数μ"周围，图形所能覆盖的变量值就少些（比如1±0.1涵盖[0.9，1.1]），于是都挤在一块，图形上呈现瘦高型。

反之，"标准差σ"越大，数据跨度就比较大，分散程度大，所覆盖的变量值就越多（比如1±0.5涵盖[0.5，1.5]），图形呈现“矮胖型”。

*所以, 你可以简单的把 标准差σ, 理解成是一个人的"腰围", 数值越小, 他就越瘦高; 腰围数值越大, 就越矮胖.*

我们可以对照上图直观地看下: 图中黄色曲线为A，蓝色曲线为B，紫红色曲线为C。如图，我们可以看到均数的大小, 决定了曲线的位置; 标准差的大小, 决定了曲线的胖瘦。

A和B的均值一样，但标准差不同，所以形状不同，根据我们的描述，图形越瘦高，标准差越小，图形越扁平，标准差越大。确实如此，图中B的标准差是1/2，小于A的标准差1。
|===


.标题
====
例如：


[options="autowidth" cols="1a,1a"]
|===
|Header 1 |Header 2

|*要求的数据* :

要求:  P（30 < X < 45）

|小明每天上学的通勤时间是一个随机变量X，这个变量服从正态分布。 +
统计他过去20天的通勤时间（单位：分钟）：26、33、65、28、34、55、25、44、50、36、26、37、43、62、35、38、45、32、28、34。 +
现在, 我们想知道他上学花30~45分钟的概率是多少? -- 即求:  P（30 < X < 45）.


|*第1步: 我们首先要拿到这两个关键变量: 均数μ, 标准差σ.*

均数μ = 38.8（分钟） +
标准差σ = 11.4（分钟）

|简单起见, 我们就用他这20天的数据, 来算出 "均数μ" 和 "标准差σ".

得到:

- 均数μ = 38.8（分钟） +
- 标准差σ = 11.4（分钟）


|*第2步: 我们要进行"标准化", 又称"z变换"*

原始的 P(30 ≤ X ≤ 45) , 经过z变换后, 就成了:  P(-0.77 ≤ Z ≤ 0.54)

|"z变换" -- 即把服从"一般正态分布"的随机变量, 变成为"服从均数μ为0，标准差σ为1" 的"标准正态分布"。

*经过"标准化"后，原来的曲线的形状不会变化，即不会改变胖瘦，只是位置发生平移.*

image:img/0159.jpg[,]

本例中, 经过"标准化"后, 均数μ 就从1010, 移到了0的位置.

这样后, 对于服从"标准正态分布"的随机变量，我们就专门用 z 来表示了。


|*标准化(z变换)的计算公式 stem:\[new X= \frac{oldX-"平均值μ"} {"标准差σ"} \]*

|*"标准化"的计算公式为：* +
原始的, 要求的是:  P（30分钟 < X < 45分钟） +
将首尾的30 和40,  *先减去"平均值μ"*(=38.8), *再除以"标准差σ"*(=11.4), 即可.

即:

- 对于30, z变换后的值就是: （30-38.8）/ 11.4 = - 0.77
- 对于45, z变换后的值就是: （45-38.8）/ 11.4 = 0.54

这样后, 原始的 P(30 ≤ X ≤ 45) 就被我们转换成了:  P(-0.77 ≤ Z ≤ 0.54)


|*用z值表, 来找到对应的概率值*


|完成z变换，我们就通过可以利用"z值表", 来找到对应的概率值.

image:img/0160.jpg[,]

再三强调，*图中阴影部分的面积, 代表的是: Z ≤ z的概率（注意是“≤”）*

还有两个根据定义成立的两个公式, 是：

- P(Z ≥ z) = 1- P(Z ≤ z)
- P(Z ≤ -z) = 1 - P(Z ≤ z)  <-因为钟形曲线的图形, 是对称的关系.

所以, 本例要求的 P(-0.77 ≤ Z ≤ 0.54), 就等于 = P(Z ≤ 0.54) – P(Z ≤ -0.77)

因此, 我们只要找到 Z≤0.54 和 Z≤-0.77 对应的概率值后, 直接把它们相减, 就得到了答案.

先看 Z≤0.54 的P值.  第一个小数是5, 就在表格的最左边那一列，找到0.5. 第二个小数是4，就定位到"顶行"的4那一列. 得到 0.7054.

image:img/0161.jpg[,]


同样, 找到 Z≤-0.77 对应的P值, 是0.2206.

所以,  +
\begin{align*}
P(-0.77 ≤ Z ≤ 0.54)
&= P(Z ≤ 0.54) – P(Z ≤ -0.77) \\
&= 0.7054 - 0.2206 \\
&= 0.4848
\end{align*}

可见, 小明上学通勤时间花费30~45分钟的概率, 将近是50%.
|===
====

---

==== 正态分布中, 运用十分广泛的三个百分数：68%，95%，99.7%.

对于"标准正态分布", 它的均数μ =0，标准差σ =1.

并且:

image:img/0162.jpg[,]

image:img/0163.jpg[,]

image:img/0164.jpg[,]

虽然理论上, "正态随机变量"可以取无数个值，定义域是整个实数轴，但实际上, **在[-1，1]这个区间就包含了它可以取的68%的值，[-2，2]区间包含了95%的值，[-3，3]包含了它可能取的99.7%的值。** 这里的1，2，3分别代表一个、两个, 和三个标准差。

*所以，根据这些统计规律，我们就可以推断出: 一个服从"标准正态分布"的变量，它的取值不太可能超过2，极不可能超过3。*

另外，这里虽然是以"标准正态分布"为例进行说明，但这个性质, 是完全可以推到"普通的正态分布"的变量的。百分数不变，不过"均数μ"和"标准差σ"不再是0和1，而是代入具体分布的"均数"和"标准差"值即可。

.标题
====
例如： +
某小学, 学生身高的数据有: +
平均值μ = 1.4米 +
标准差σ = 0.15米

身高一般是服从"正态分布"的. 则, 我们就可以知道:

- 这个学校有68%的学生, 身高在1.25到1.55 之间. 这首尾两个数值, 就是 "均值1.4" 加减 "标准差0.15" 得到的（均数加减一个标准差）.
- 有95%的学生, 身高在1.1到1.7之间（"均数"加减两个"标准差"）

image:img/0166.png[,]




反过来计算也行, 如果我们知道了某个变量的95%区间的取值（关于"均值"对称），我们就可以算出对应的"均数"和"标准差"，进而就能几乎知道一切。

image:img/0165.jpg[,]
====



---

== 正态分布的"概率密度函数" (用小写的 φ 表示) ->  stem:[ φ(x)= \frac{1} {\sqrt{2π} \cdot σ} \cdot e^{-\frac{(x-μ)^2} {2σ^2}}]

正态分布的"概率密度函数" Probability Density Function :

image:img/0170.webp[,]

image:img/0171.webp[,]


记作: stem:[ X ~ N(μ, σ^2)]   ← 称为: X服从"参数为μ, σ的正态分布(或高斯分布)". +

- 这里的 N, 就是正态分布 (Normal distribution) 的英文首字母.
- μ 是 "平均值"
- σ 是 "标准差".  +
另外要注意: 这里写的是 stem:[ N(μ, σ^2)], 即第二个参数, 是stem:[ σ^2]的值, 而不是σ的值!  所以, 比如对于 N(1, 100)来说, 其 μ=1,  stem:[ σ^2=100], 即 σ=10

*对正态分布的"概率密度函数"求积分, 即其面积=1.*  其证明过程如下:

---

== 正态分布的"累加函数"(即"概率分布函数") (用大写的 Φ 表示) -> stem:[Φ]

*对"概率密度函数 f(x)"求积分, 其曲线下的阴影面积就是"累加函数 F(x)". +
反过来, 对"累加函数 F(x)"求导, 结果就是得到"概率密度函数 f(x)"*


#芬(累加函数) 岛(的导数) 盖(是概率函数),  即: stem:[ F'(x) = f(x)]#

image:img/0100.png[,]

image:img/0177.png[,]

---


== 正态分布的性质

=== 性质1: 其概率密度函数 y=φ(x) 的曲线图形, 以 "x=均值μ" 为对称轴. 所以"正态分布" 的函数图像, 形状是个"钟形曲线".

image:img/0178.png[,]

所以, 在 x=μ 处时, 函数就达到 y值的最大点, 即此时 stem:[ y= \frac{1} {\sqrt{2π} \cdot σ} ] : +
image:img/0179.png[,]

image:img/0180.png[,]


---

=== 性质2 : 其概率密度函数 y=φ(x) 的曲线图形, 以x轴为渐近线

就是说, 曲线的两端, 无限接近于 y=0, 而不会掉落到 -y 领域上去.

---

=== 性质3: 其概率密度函数 y=φ(x), 在 stem:[ x= μ \pm σ] 处有"拐点"

image:img/0181.png[,]

不过, "拐点"在概率论里面, 用的不多.

---

=== 性质4:  μ 和 σ 是分别控制图像的什么方面

① 若 σ固定, 对称轴μ变化, 图像就是会"左右移动".

② 若对称轴μ固定, σ变化 :

-> 若σ 变小: 因为 在x=μ处, y有最大值是 stem:[ \frac{1} {\sqrt{2π} \cdot σ}]. 所以 当σ变小时, 分母变小, 则分数值就变大, 即y值变大, 所以图像会拉高, 变瘦高.

-> 若σ 变大: 则最高点的y值变小, 图像会压低, 变矮胖.

但注意, 无论是变瘦高, 还是变矮胖, 曲线下的阴影面积, 始终是=1, 不变的!

image:img/0191.png[,]


---

== ----- -----

---


== 标准正态分布 standard normal distribution -> 即当 均值μ=0, 标准差σ=1 时 的"正态分布"

image:img/0182.png[,]

即:

[options="autowidth"]
|===
|标准正态分布 (对称轴μ=0, σ=1) |Header 2

|其概率函数
|stem:[φ_0(x)= \frac{1} {\sqrt{2π}} \cdot e^{-\frac{x^2} {2}} ]

|其累加函数 (即分布函数)
|stem:[ Φ_0(x)= \frac{1} {\sqrt{2π}} \int_{-∞}^x (e^{-\frac{x^2} {2}}) dx]
|===

---

== "标准正态分布"的性质

=== 性质1: 因为它的 μ=0, 所以它的函数曲线, 关于 x=0 对称, 即y轴是对称轴.

所以它就是个偶函数.  有: "概率密度函数" stem:[ φ_0(x) = φ_0(-x) ]   ← 我们在下标处加个0, 来表示它是"标准"的正态分布函数的 "概率函数"或"累加函数".

并且, 其"累加函数"有: *stem:[ Φ_0(-x) = 1-  Φ_0(x) ]*   ← 这个公式很重要! +
比如: stem:[ Φ_0(-4) =1- Φ_0(4)]

image:img/0183.png[,]

.标题
====
例如： +
image:img/0186.png[,]

image:img/0187.png[,]
====



---


== 正态分布的值, 怎么算? -- 查表

一般, 书上给出的都是"标准正态分布"的表, 所以如果你是普通的"正态分布", 必须先把它转成"标准正态分布", 再来查表.

并且, 表的范围, 只给出了 stem:[ 0 \leq x < 5] 的值. 对于 stem:[ x ≥ 5] 的值, 因为此时的曲线高度, 即y值, 已经非常靠近y=0了, 所以我们就都可以认为, 对于 x≥5 的 "概率密度函数 stem:[ φ_0(x)]"的y值, 都=0.

image:img/0184.png[,]

同样, 对于 x≥5 时, 其位置已经非常靠近整个曲线的右端末尾了, 而整个函数曲线下的面积也就=1, 所以, 在x≥5 处的"累加函数stem:[ Φ_0(x)]", 其值我们就可以认为是1.

即:
\begin{align}
x \geq 5 时: \\
→ 概率函数 φ_0(x) ≈ 0 \\
→ 累加函数 Φ_0(x) ≈ 1 \\
\\
x ≤ -5 时: \\
→ 概率函数 φ_0(x) ≈ 0 \\
→ 累加函数 Φ_0(x) ≈ 0 \\
\end{align}

---


== 普通的"正态分布", 怎样转化成"标准正态分布"?

image:img/0185.png[,]


.标题
====
例如： +
image:img/0188.png[,]
====


.标题
====
例如： +
image:img/0190.png[,]

image:img/0189.png[,]
====


.标题
====
例如： +
image:img/0192.png[,]

这个例题, 就引出了 "3σ准则".
====

---

== 3σ准则

image:img/0193.png[,]

---

== 分位数 Quantile


**分位数, 指的就是连续数据的"概率密度函数"中的一个点，这个点对应概率p。**

*比如下图,  stem:[x_p] 就是"p分位数". 意思是: 在stem:[x_p]这个点处, 该点左侧的曲线下的面积值=p . 即 stem:[P{X \leq x_p} = p]*

image:img/0194.png[,]

---

=== 上侧分位数

如果有一个 stem:[x_α]点 (0<α<1), 它的stem:[P{X \geq x_α}= "面积"α], 那么我们就称:  stem:[x_α] 为X的"上侧分位数".

image:img/0195.png[,]

在数理统计教程中，会把"标准正态分布"的"上侧分位数", 记为：stem:[u_α]




---

=== 上侧α分位数 <- 它其实就是 x轴上的一个点, 变量名写作:  stem:[u_{"右侧曲线下的面积"}]

X 是个正态分布, 即 X~N(0,1).  给定 α是 (0<α<1), 你去找 stem:[u_α], 使得 stem:[P{X>u_α}=α], 则, 这个 stem:[U_α] 就叫"上α分位数".

image:img/0196.png[,]

image:img/0197.png[,]

上α分位数, 它其实就是 x轴上的一个点, 变量名写作:  stem:[u_{"右侧曲线下的面积"}]

image:img/0198.png[,]


---

== "正态总体"下的抽样分布

*下面的规律都是基于"总体"服从"正态分布"的前提*，这里只需要总体是"正态分布"即可，不需要是"标准正态分布"。


[options="autowidth"]
|===
|Header 1 |Header 2

|关于"样本均值stem:[ \overline{X}]"的分布
|样本均值经过以下"标准化"后，就服从"标准正态分布": +
image:img/0812.svg[,]

即样本均值的期望=总体期望，样本均值的方差=总体方差的n分之一。


若将分母中的"总体标准差σ"改为"样本标准差S"，则服从"自由度为n-1的 t分布"： +
image:img/0813.svg[,]

|关于"样本方差stem:[ S^2]"的分布
|样本方差乘以系数后，服从自由度为 n-1的卡方分布： +
image:img/0814.svg[,]

需要注意的是，这里的自由度是n-1，因为这里样本方差是用每个样本减去样本均值。如果改为减去总体均值，其他内容不变，则服从自由度为n的卡方分布。因为样本均值多了一个约束（均值公式），因此自由度少了一个。

|关于"样本均值stem:[ \overline{X}]"和"样本方差stem:[ S^2]"的关系
|"样本均值"和"样本方差"相互独立。

|两个"正态总体"时，两样本的关系
|上面讲到的几个都是在"单个正态总体"的情况下。当有"两个正态总体"时，两个样本的方差和两个总体方差, 有以下分布： +
image:img/0815.svg[,]  +
即处理后的分布服从F分布。

另外，一种特殊情况下，当 image:img/0816.svg[,] 时， +
image:img/0815.svg[,]

其中，image:img/0818.svg[,]
|===




