
= 统计 - 检验假设
:sectnums:
:toclevels: 3
:toc: left

---


== 解释

=== 解释 (刘嘉概率讲座)

一女的说, 她能分辨 奶茶先加的奶, 还是先加的茶, 那我们就来检验一下.

我们设 "原假设 H0" 为: 她无法分辨, 在撒谎. +
"备择假设 H1" 就为: 她能分辨.

image:img/0630.svg[,500]

假设她连续说对了5次 (即 成功概率 stem:[ = 0.5^5 =0.03125 < 5% ], 即落在 H0 的拒绝域中 (属于H0的小概率事件). 说明 她大概率不属于 H0模型描述的世界中, 而是属于 H1 的世界中.

- HO 模型中, "拒绝域"所占的概率面积, 就是"显著性水平".
- 样本结果所处的位置, 到 H0模型曲线更极端方向, 这段区域的面积 (所占的概率), 就是 P值.

image:img/0631.png[,]

*H0模型, 就相当于一个公司. 接受域, 即H0会"留人"的地方. 拒绝域, 即 H0会"踢人, 裁人"的地方. 样本如果处在"拒绝域"中, 就很有可能被H0踢出去. 样本在H0公司里呆不下.*

拒绝域(即"显著性水平")的面积, 设置的越小, 样本就越难落入"拒绝域"的范围中. 即, 你将H0的小概率事件范畴, 缩得非常小. 即 H0的"接受域"范围, 包容度非常大. 这就导致很少有样本能被H0不接受.


"假设检验"一诞生, 就席卷了各个领域，几乎成为现代医学、心理学、经济学、社会学,乃至计算机科学等学科研究的底层方法之一。

不过, "假设检验"也有自身的问题:

[options="autowidth"]
|===
|Header 1 |Header 2

|1.会忽视小概率事件
|如果样本落在H0的拒绝域中, 样本就可能被踢出H0模型. 但是, H0的拒绝域(即对 H0 来说是"小概率事件"的地方), 并不意味着它里面的事件就不会发生.

H0 中的"小概率事件"依然是可能发生的. 美国有个人, 连续两次中了彩票大奖, 就是小概率事件发生了.

|2.容易导致"系统性偏差".
|*样本的位置, 决定了P值这个概率. 而样本的选取, 是可以人为选择的, 你选不同的样本, 就能得到不同的P值。* 这就带来了可作假的操作空间:

*假设你本来就是想让样本脱离 H0模型, 我们只要不断改变样本，就能不断改变P值，最终总能找到一个非常小的P值, 让样本一定落在 H0 的"拒绝域"里面. 来让样本被H0模型提出去 (即得出"样本不属于H0模型世界"的结论). 而别人是不知道你怎么得到这个P值的, 他们就容易被你误导, 相信了你.*

这种"操作方法上的误差", 就属于"系统性偏差" systematic deviation 中的一种.

所以, 孤证不立. 一次试验可能有很大的偶然性, 只有很多试验都验证了某个结论,我们才能相信它。 +
*也因此，严谨的科学论文中, 一般不说“我们证明了xx”，而是说“我们认为: xx和xx有统计上的"显者性".*


不同的领域, H0模型的"拒绝域"(显著性水平)的面积设置(即"临界值"处在X轴上的哪个位置), 是不同的. 比如, *物理学领域, H0模型是假设"没有新发现". "拒绝域"就要越小越好, 否则, 样本轻易的落在"拒绝域"中, 就会导致样本被踢出 H0, 而变成支持了 H1模型 (即"有新的物理发现"), 这就很容易导致"各种牛鬼蛇神的虚假结论"被"发现"出来.* 经常有物理学发现被证明不靠谱.

image:img/0632.svg[,600]

像大型强子对撞机, 发现希格斯玻色子这个实验, 就需要百万分之一的"显著性"标准,是5%的20万分之一。

|3.用错了"概率分布模型", 也会导致错误的结论.
|*一般"假设检验"只用于"正态分布", 但如果一个随机事件不是正态分布的, 却偏要用假设检验，当然就出错了.*

比如, 国家统计局说,2019年,北京平均月工资是7828.49元。你想判断这个数据靠不靠谱, 能用"假设检验"吗? 可以随机选择50个人，看看他们的平均收入在不在7800元附近吗? 当然不能。因为**人的收入, 不服从正态分布,而是服从"幂率分布"。而幂率分布，根本没有"均值μ"和"标准差σ"。 所以, 再用收入的均值来做"假设检验"就没有意义了。**

即使都属于"正态分布", 用不对也一样会错。比如, 明明是菲律宾人的身高问题, 你却拿出亚洲人的身高分布做比较，或者拿出菲律宾人的智商分布做比较，分布都不是一个，结果当然也是错的。
|===



---

== 检验假设

=== stem:[ H_0] 永远用来存放"保守估计", 或对你有利的估计, 你"优先倾向"的那一种情况.

image:img/0605.png[,600]

image:img/0606.webp[,600]

image:img/0607.webp[,]

*即, stem:[ H_0]是悲观主义者的优先选择(所以称为"保守选择". 以前是什么状况, 现在依然是什么状况),  stem:[ H_1] 就留给乐观选择(新的比旧的好, 新的在效能上超过了旧的).*



比如, 新药问题:
[options="autowidth"]
|===
| 到底选哪个作为stem:[ H_0] ? |stem:[ H_0] (你所倾向的,第一选择的) | stem:[ H_1](只有第一选择被推翻, 才会选这第二选择的)|就意味着

|→
|新药无效
|新药有效
|你更相信新药无效 (H0), 不想它上市. 除非有"有效"的证据 (H1)推翻它

|→
|新药有效
|新药无效
|你更相信新药有效 (H0), 应该上市, 除非有强烈的证据 (H1)证明它"无效"
|===

image:img/0608.png[,600]

image:img/0609.png[,600]

---

=== 两类错误: 1.弃真 (H0为真, 你却没选它), 2.纳伪(H0为假, 你却选了它)

人们会犯两类错误:

假设检验的最终目的是：去伪存真， +
那么它对应的两类错误, 就是:弃真存伪。

接受或拒绝H0，都可能犯错误:

- I类错误 (或α错误) ——弃真错误，发生的概率为α.  +
即 "h0为真, 我们却没选它"的概率, 是α.  +
那么, "h0为真, 我们成功选了它"的概率就是 1-α.  +

- II类错误 (或β错误) ——取伪错误，发生的概率为β.  +
即 "h0为假, 我们却选了它"的概率就是 β.  +
那么, "h0为假, 我们成功没选它"的概率就是 1-β.

[options="autowidth"]
|===
|原假设 stem:[ H_0] | 备选假设 stem:[ H_1] | 说明

|为真
|为假 +
(你却选了这个假的 stem:[ H_1])
|← 你拒绝了"真的原假设", 你犯了"弃真"型的错误.(第一类错误)

犯这类错误的概率不超过α，即: P{拒绝H0/H0为真}≤α

α 错误出现原因: +
我们只抽了一个样本，而个别的样本可能是特殊的，不管你的抽样多么符合科学抽样的要求。理论上讲，*在 3000 个员工中随机抽取 50 人作为调查样本，有很多种构成样本的可能性，相当于 3000 选 50，这个数目是很大的。这样，在理论上就有存在很多个样本平均数。也就是说，由于小概率事件的出现，我们把本来真实的原假设拒绝了。这就是 α 错误出现的原因。*



|为假 +
(你却选了这个假的 stem:[ H_0])
|为真
|← 你没有拒绝"假的原假设", 依然选择了它. 你犯了"纳伪"型的错误. (第二类错误)

犯这类错误的概率记为β，即: P{接受H0/H1为真}＝β
|===

α与β是在两个前提下的概率，所以α+β不一定等于1. +
在其他条件不变的情况下，α与β不能同时增加或减少（因为对于同一个H0,一个拒绝一个接受）.

image:img/0610.svg[,600]

如上图,  +
H0:没有怀孕 (因为"原假设为没有确凿证据一般不推翻的假设"，所以人大多数情况下,我们不认为他们是处在怀孕状态的) +
H1:怀孕了

上图左: "原假设H0"为"没有怀孕"，男人肯定是落在 H0的"接受域"中的. 但是检验的结果落在了 H0的"拒绝域"中，因而拒绝没有怀孕的原假设H0. 这就犯了第一类错误: 弃真。

上图右: "原假设H0"为"没有怀孕"，这个怀孕的女人肯定是落在 H0的"拒绝域"中的, 她是怀孕的. 但检验结果却落在了 H0的"接受域"中，接受"没有怀孕"的原假设. 这就犯了第二类错误: 存伪.

---

=== 1. "接受域", 就是"置信水平". 2."拒绝域" 就是"显著性水平".

image:img/0611.webp[,]

如上图, *一个总体模型(属于h0 的模型), 是被分为"置信水平"(接受域)和"显著性水平"(拒绝域)两部分. 这两部分是不同的两个群体, 即这两个群体是有"显著性差异"的. "显著性水平"就是 H0模型中的"小概率事件"。*

→ *当我们的样本, 或者实验结果，落在了"置信水平"(接受域)，我们就认为该样本, 属于"置信水平"的总体，也就是h0成立时的模型 (h0的"接受域"中). 即, 我们大概率相信: 样本是活在H0模型中的.*

→ *当我们的样本, 或者实验结果, 落在了"显著性水平"(h0的"拒绝域"中)，那么我们就认为这个样本与h0模型, 是有"显著性差异"的，换言之, 这个样本不太可能活在H0模型中, 而更有可能是属于"h1"模型中的。*

*我们首先假设h0成立，显著性水平(拒绝域)设为0.05. 我们的样本或者实验结果, 如果恰好落在了"显著性水平"(拒绝域)内，即发生了"小概率事件"，毕竟该事件发生的概率不到5%。小概率事件一发生，我们就可以认为, 对于样本的结果反映, 它(样本)不太可能处在H0模型中, 因为在H0模型下, 这个样本会发生的概率太小了。 所以, 这个样本, 就更有可能活在H1模型中, 而不是H0模型中.*


对于这两类错误, 我们采取的应对策略, 有: N-P准则 (Neyman-Pearson lemma)

原假设H0, 在检验前被视为是正确的，除非有充分的证据，否则我们不轻易推翻原假设。 +
通常我们选择极小的"显著水平"(拒绝域) 如 0.01 或 0.05, 来确保我们不会推翻H0。 即我们将H0模型的拒绝域, 划得尽可能小. 这样, 样本就很难落入 H0的拒绝域中, 而是大概率落在"接受域"中. 这样, 样本就大概率是活在H0模型世界中的, 而不是其他模型世界中.

image:img/0612.svg[,500]

[options="autowidth"]
|===
|Header 1 |Header 2

|"显著性水平", 就是"拒绝域"
|**如果样本的结果, 落在 H0 的"拒绝域"(即H0中的"小概率事件")中, 那就说明, 你这个"样本"大概率是不属于 H0模型世界中的 (而是属于其他模型世界, 比如 H1中). H0中的"拒绝域"所占的概率范围, 就是"显著性水平 α" (significant level). 所以, "显著性水平"是一个概率值. (即 H0中的"小概率事件"它的概率值.)**

拒绝域α 占多少概率, 由研究者自己来确定. 常见的α 可取 0.01, 0.05, 0.1 等.

image:img/0613.png[,500]

|双侧检验
|就是看: 是否   "\|样本的值\| > 临界值",  大于临界值, 即样本落入了 H0 的拒绝域中, 就说明 样本大概率不属于 H0模型世界中.

双侧检验拒绝域： +
image:img/0614.webp[,500]

image:img/0620.webp[,]


|左侧检验
|就是看: 是否   "样本的值 < 临界值".  小于临界值, 即样本落入了 H0 的左侧拒绝域中, 就说明 样本大概率不属于 H0模型世界中.

左侧检验拒绝域： +
image:img/0615.webp[,500]

image:img/0619.webp[,]


|右侧检验
|就是看: 是否   "样本的值 > 临界值".  >于临界值, 即样本落入了 H0 的右侧拒绝域中, 就说明 样本大概率不属于 H0模型世界中.

右侧检验拒绝域： +
image:img/0616.webp[,500]

image:img/0618.webp[,]

|P值（P-value）
|样本结果所在的x点处, 朝 H0曲线 更极端方向走, 这段范围的面积(所占概率值), 就是P值.

image:img/0621.webp[,]

image:img/0622.png[,]

*P值越小, 就说明"你这个样本结果 所占的 H0 的面积越小, 越处于H0曲线的两边极端处", 即 P值越可能落入 "H0 的拒绝域"中, 即说明 "样本 越大可能性是不属于 H0模型世界中的".*

image:img/0623.webp[,500]


|===

注意: 样本如果落在了H0的拒绝域中, 是不能100%说 样本就是绝对不属于 H0模型的, 只是"大概率"不属于 H0模型世界中. 因为H0的小概率事件, 依然是有可能发生的. 比如, 真的有人连续两次中了彩票大奖.


image:img/0617.webp[,600]

image:img/0629.webp[,]


https://www.bilibili.com/video/BV1yt4y1D7Ag/?spm_id_from=333.999.top_right_bar_window_default_collection.content.click&vd_source=52c6cb2c1143f8e222795afbab2ab1b5

37.17



---

已知大二的学生成绩(均值是 137.41), 但大一的成绩还没全部统计出来, 只有部分结果出来. 我们是否能根据手头现有的数据, 来预测一下, 大一的成绩是否会和大二的有显著差别呢?

那么我们就先假设, 大一和大二的无区别,即都属于同一个正态分布情况 (均值也是 137.41).

image:img/0465.png[,700]

image:img/0466.png[,700]

image:img/0467.png[,700]

image:img/0468.png[,700]

image:img/0469.png[,700]

image:img/0470.png[,700]

image:img/0471.png[,700]

image:img/0472.png[,700]

image:img/0473.png[,700]

image:img/0474.png[,700]

换言之, 我们更可能相信: 大一和大二的成绩, 抽样分布的曲线形状不同.

image:img/0475.png[,700]

image:img/0476.png[,700]


如果你把极端情况的范围, 从5% 缩小为 1%, 即只有"最头尾末端总共1%" (即单侧0.5%)才算极端区域.

image:img/0477.png[,700]

image:img/0478.png[,700]

image:img/0479.png[,700]

image:img/0480.png[,700]

image:img/0481.png[,700]

image:img/0482.png[,700]

image:img/0483.png[,700]

image:img/0484.png[,700]

---

